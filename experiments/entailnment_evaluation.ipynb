{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "from time import time\n",
    "import json\n",
    "from faithfulness_eval_utils.entailment_eval import evaluate_entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a98e2d0b50149019b8c5e4de0e1950d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a592db28404abc9ca7c6ce98508ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/688 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e61e908665414fbd6e39ed482dafff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452a1eb56fed448bb30597329cc243d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c3919325244648a95561d7294cb43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8fbedf8a294becaf77cb36bf366d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 5 items to `output/roberta_mnli/results.json`\n",
      "Averages written to `output/roberta_mnli/stats.json`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'statement': \"Shakespeare wrote 'Romeo and Juliet'.\",\n",
       "   'label': 'SUPPORTED',\n",
       "   'evidences': [\"William Shakespeare is credited as the author of the play 'Romeo and Juliet'.\",\n",
       "    \"'Romeo and Juliet' was first published in 1597 and is attributed to Shakespeare.\"],\n",
       "   'explanation': \"Historical records and publication attributions confirm that Shakespeare wrote 'Romeo and Juliet'.\",\n",
       "   'e2x_entail_prob': 0.38058656454086304,\n",
       "   'x2e_entail_prob': 0.6615111231803894},\n",
       "  {'statement': 'Eating carrots improves eyesight.',\n",
       "   'label': 'NOT_SUPPORTED',\n",
       "   'evidences': ['Carrots contain beta-carotene, which the body converts to vitamin A, a nutrient important for vision.',\n",
       "    'No clinical evidence shows that eating carrots prevents or cures vision problems beyond normal health benefits.'],\n",
       "   'explanation': 'While carrots provide vitamin A, there is no evidence they improve eyesight beyond maintaining normal vision.',\n",
       "   'e2x_entail_prob': 0.9374357461929321,\n",
       "   'x2e_entail_prob': 0.3243498206138611},\n",
       "  {'statement': 'Mount Everest is over 8,000 meters tall.',\n",
       "   'label': 'SUPPORTED',\n",
       "   'evidences': [\"Mount Everest's height was first measured in 1856 as 8,840 meters.\",\n",
       "    \"Recent GPS surveys have confirmed Everest's elevation at approximately 8,848.86 meters above sea level.\",\n",
       "    'Everest is the tallest mountain on Earth by elevation above sea level.'],\n",
       "   'explanation': \"Multiple measurements, historical and modern, consistently report Everest's height above 8,000 meters.\",\n",
       "   'e2x_entail_prob': 0.6474490761756897,\n",
       "   'x2e_entail_prob': 0.017947306856513023},\n",
       "  {'statement': 'Honey never spoils.',\n",
       "   'label': 'SUPPORTED',\n",
       "   'evidences': ['Archaeologists have found pots of honey in ancient Egyptian tombs over 3,000 years old that were still edible.',\n",
       "    \"Honey's low moisture and high acidity inhibit bacterial growth, allowing it to remain unspoiled.\"],\n",
       "   'explanation': 'Due to its chemical properties, honey resists spoilage and archaeological examples show it remains edible for millennia.',\n",
       "   'e2x_entail_prob': 0.9807917475700378,\n",
       "   'x2e_entail_prob': 0.0038264794275164604},\n",
       "  {'statement': 'Honey never spoils.',\n",
       "   'label': 'NOT_SUPPORTED',\n",
       "   'evidences': ['Archaeologists have found pots of honey in ancient Egyptian tombs over 3,000 years old that were still edible.',\n",
       "    \"Honey's low moisture and high acidity inhibit bacterial growth, allowing it to remain unspoiled.\"],\n",
       "   'explanation': 'Honey spoils after a week.',\n",
       "   'e2x_entail_prob': 0.0015755320200696588,\n",
       "   'x2e_entail_prob': 0.00018953019753098488}],\n",
       " {'avg_e2x_entail_prob': 0.5895677332999185,\n",
       "  'avg_x2e_entail_prob': 0.2015648520551622})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../sample_complex.json\") as fin:\n",
    "    data = json.load(fin)\n",
    "\n",
    "evaluate_entailment(\n",
    "    data,\n",
    "    result_dir=\"output/roberta_mnli\",\n",
    "    tokenizer_path=\"roberta-large-mnli\",\n",
    "    model_path=\"roberta-large-mnli\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++\n",
      "Processing model setup: deepseek_r1_32b_cot\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\deepseek_r1_32b_cot\\covid_fact_depseek_r1_cot.json...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "evaluate_entailment() missing 1 required positional argument: 'result_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dataset_path, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[32m     53\u001b[39m     data = json.load(fin)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[43mevaluate_entailment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstats_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstats_output_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresults_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresults_output_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mroberta-large-mnli\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mroberta-large-mnli\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m t3 = time()\n\u001b[32m     63\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     64\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFinished evaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Time elapsed since start: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(t3\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mt1)\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[32m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m minutes, since last file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(t3\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mt2)\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[32m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m minutes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     65\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: evaluate_entailment() missing 1 required positional argument: 'result_dir'"
     ]
    }
   ],
   "source": [
    "SKIP_EXISTING_RESULTS: Literal[\"auto\", \"ask\"] = \"auto\"\n",
    "\n",
    "data_path = os.path.normpath(\"../inference_outputs/converted_outputs/\")\n",
    "model_setup_dirs = os.listdir(data_path)\n",
    "\n",
    "t1 = time()\n",
    "\n",
    "for model_setup_dir in model_setup_dirs:\n",
    "    if not os.path.isdir(os.path.join(data_path, model_setup_dir)):\n",
    "        continue\n",
    "\n",
    "    print(\"\\n\\n+++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(f\"Processing model setup: {model_setup_dir}\")\n",
    "\n",
    "    dataset_files = os.listdir(os.path.join(data_path, model_setup_dir))\n",
    "    if not dataset_files:\n",
    "        print(f\"No files found in {model_setup_dir}...\")\n",
    "        raise ValueError()\n",
    "\n",
    "    for dataset_file in dataset_files:\n",
    "        if not dataset_file.endswith(\".json\"):\n",
    "            continue\n",
    "\n",
    "        t2 = time()\n",
    "        dataset_path = os.path.join(data_path, model_setup_dir, dataset_file)\n",
    "        result_dir = os.path.join(\"output\", \"entailment\", model_setup_dir)\n",
    "        stats_output_filename = f\"{dataset_file.replace('.json', '.stats.json')}\"\n",
    "        results_output_filename = f\"{dataset_file.replace('.json', '.results.json')}\"\n",
    "\n",
    "        if os.path.exists(\n",
    "            os.path.join(result_dir, stats_output_filename)\n",
    "        ) or os.path.exists(os.path.join(result_dir, results_output_filename)):\n",
    "            print(\n",
    "                f\"Either {stats_output_filename} or {results_output_filename} already exists in {result_dir}.\"\n",
    "            )\n",
    "            if SKIP_EXISTING_RESULTS == \"ask\":\n",
    "                if (\n",
    "                    input(\"Do you want to recreate these files? (y/n): \")\n",
    "                    .strip()\n",
    "                    .lower()\n",
    "                    != \"y\"\n",
    "                ):\n",
    "                    print(\"Skipping these files...\")\n",
    "                    continue\n",
    "            elif SKIP_EXISTING_RESULTS == \"auto\":\n",
    "                print(\n",
    "                    f\"Skipping {dataset_path} as results already exist in {result_dir}. Please check manually if results are valid.\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "        print(f\"\\nEvaluating {dataset_path}...\")\n",
    "        with open(dataset_path, encoding=\"utf-8\") as fin:\n",
    "            data = json.load(fin)\n",
    "\n",
    "        evaluate_entailment(\n",
    "            data=data,\n",
    "            stats_filename=stats_output_filename,\n",
    "            results_filename=results_output_filename,\n",
    "            result_dir=result_dir,\n",
    "            tokenizer_path=\"roberta-large-mnli\",\n",
    "            model_path=\"roberta-large-mnli\",\n",
    "        )\n",
    "        t3 = time()\n",
    "        print(\n",
    "            f\"Finished evaluating {dataset_path}. Time elapsed since start: {(t3 - t1) / 60:.2f} minutes, since last file: {(t3 - t2) / 60:.2f} minutes.\"\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
