{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from faithfulness_eval_utils.entailment_eval import evaluate_entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a98e2d0b50149019b8c5e4de0e1950d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a592db28404abc9ca7c6ce98508ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/688 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e61e908665414fbd6e39ed482dafff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452a1eb56fed448bb30597329cc243d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c3919325244648a95561d7294cb43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8fbedf8a294becaf77cb36bf366d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 5 items to `output/roberta_mnli/results.json`\n",
      "Averages written to `output/roberta_mnli/stats.json`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'statement': \"Shakespeare wrote 'Romeo and Juliet'.\",\n",
       "   'label': 'SUPPORTED',\n",
       "   'evidences': [\"William Shakespeare is credited as the author of the play 'Romeo and Juliet'.\",\n",
       "    \"'Romeo and Juliet' was first published in 1597 and is attributed to Shakespeare.\"],\n",
       "   'explanation': \"Historical records and publication attributions confirm that Shakespeare wrote 'Romeo and Juliet'.\",\n",
       "   'e2x_entail_prob': 0.38058656454086304,\n",
       "   'x2e_entail_prob': 0.6615111231803894},\n",
       "  {'statement': 'Eating carrots improves eyesight.',\n",
       "   'label': 'NOT_SUPPORTED',\n",
       "   'evidences': ['Carrots contain beta-carotene, which the body converts to vitamin A, a nutrient important for vision.',\n",
       "    'No clinical evidence shows that eating carrots prevents or cures vision problems beyond normal health benefits.'],\n",
       "   'explanation': 'While carrots provide vitamin A, there is no evidence they improve eyesight beyond maintaining normal vision.',\n",
       "   'e2x_entail_prob': 0.9374357461929321,\n",
       "   'x2e_entail_prob': 0.3243498206138611},\n",
       "  {'statement': 'Mount Everest is over 8,000 meters tall.',\n",
       "   'label': 'SUPPORTED',\n",
       "   'evidences': [\"Mount Everest's height was first measured in 1856 as 8,840 meters.\",\n",
       "    \"Recent GPS surveys have confirmed Everest's elevation at approximately 8,848.86 meters above sea level.\",\n",
       "    'Everest is the tallest mountain on Earth by elevation above sea level.'],\n",
       "   'explanation': \"Multiple measurements, historical and modern, consistently report Everest's height above 8,000 meters.\",\n",
       "   'e2x_entail_prob': 0.6474490761756897,\n",
       "   'x2e_entail_prob': 0.017947306856513023},\n",
       "  {'statement': 'Honey never spoils.',\n",
       "   'label': 'SUPPORTED',\n",
       "   'evidences': ['Archaeologists have found pots of honey in ancient Egyptian tombs over 3,000 years old that were still edible.',\n",
       "    \"Honey's low moisture and high acidity inhibit bacterial growth, allowing it to remain unspoiled.\"],\n",
       "   'explanation': 'Due to its chemical properties, honey resists spoilage and archaeological examples show it remains edible for millennia.',\n",
       "   'e2x_entail_prob': 0.9807917475700378,\n",
       "   'x2e_entail_prob': 0.0038264794275164604},\n",
       "  {'statement': 'Honey never spoils.',\n",
       "   'label': 'NOT_SUPPORTED',\n",
       "   'evidences': ['Archaeologists have found pots of honey in ancient Egyptian tombs over 3,000 years old that were still edible.',\n",
       "    \"Honey's low moisture and high acidity inhibit bacterial growth, allowing it to remain unspoiled.\"],\n",
       "   'explanation': 'Honey spoils after a week.',\n",
       "   'e2x_entail_prob': 0.0015755320200696588,\n",
       "   'x2e_entail_prob': 0.00018953019753098488}],\n",
       " {'avg_e2x_entail_prob': 0.5895677332999185,\n",
       "  'avg_x2e_entail_prob': 0.2015648520551622})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../sample_complex.json\") as fin:\n",
    "    data = json.load(fin)\n",
    "\n",
    "evaluate_entailment(\n",
    "    data,\n",
    "    result_dir=\"output/roberta_mnli\",\n",
    "    tokenizer_path=\"roberta-large-mnli\",\n",
    "    model_path=\"roberta-large-mnli\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.normpath(\"../outputs/converted_outputs/\")\n",
    "model_setup_dirs = os.listdir(data_path)\n",
    "\n",
    "for model_setup_dir in model_setup_dirs:\n",
    "    if not os.path.isdir(os.path.join(data_path, model_setup_dir)):\n",
    "        continue\n",
    "    dataset_files = os.listdir(os.path.join(data_path, model_setup_dir))\n",
    "    if not dataset_files:\n",
    "        print(f\"No files found in {model_setup_dir}...\")\n",
    "        raise ValueError()\n",
    "\n",
    "    for dataset_file in tqdm(dataset_files, desc=f\"Processing {model_setup_dir}\"):\n",
    "        if not dataset_file.endswith(\".json\"):\n",
    "            continue\n",
    "\n",
    "        dataset_path = os.path.join(data_path, model_setup_dir, dataset_file)\n",
    "        result_dir = os.path.join(\"output\", \"geval\", model_setup_dir)\n",
    "\n",
    "        print(f\"Evaluating {dataset_path}\")\n",
    "        with open(dataset_path, encoding=\"utf-8\") as fin:\n",
    "            data = json.load(fin)\n",
    "\n",
    "        evaluate_entailment(\n",
    "            data=data,\n",
    "            result_dir=\"output/roberta_mnli\",\n",
    "            tokenizer_path=\"roberta-large-mnli\",\n",
    "            model_path=\"roberta-large-mnli\",\n",
    "        )\n",
    "        print(f\"Finished evaluating {dataset_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
