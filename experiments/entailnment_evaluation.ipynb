{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "from time import time\n",
    "import json\n",
    "from faithfulness_eval_utils.entailment_eval import evaluate_entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a98e2d0b50149019b8c5e4de0e1950d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a592db28404abc9ca7c6ce98508ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/688 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e61e908665414fbd6e39ed482dafff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452a1eb56fed448bb30597329cc243d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c3919325244648a95561d7294cb43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8fbedf8a294becaf77cb36bf366d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 5 items to `output/roberta_mnli/results.json`\n",
      "Averages written to `output/roberta_mnli/stats.json`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'statement': \"Shakespeare wrote 'Romeo and Juliet'.\",\n",
       "   'label': 'SUPPORTED',\n",
       "   'evidences': [\"William Shakespeare is credited as the author of the play 'Romeo and Juliet'.\",\n",
       "    \"'Romeo and Juliet' was first published in 1597 and is attributed to Shakespeare.\"],\n",
       "   'explanation': \"Historical records and publication attributions confirm that Shakespeare wrote 'Romeo and Juliet'.\",\n",
       "   'e2x_entail_prob': 0.38058656454086304,\n",
       "   'x2e_entail_prob': 0.6615111231803894},\n",
       "  {'statement': 'Eating carrots improves eyesight.',\n",
       "   'label': 'NOT_SUPPORTED',\n",
       "   'evidences': ['Carrots contain beta-carotene, which the body converts to vitamin A, a nutrient important for vision.',\n",
       "    'No clinical evidence shows that eating carrots prevents or cures vision problems beyond normal health benefits.'],\n",
       "   'explanation': 'While carrots provide vitamin A, there is no evidence they improve eyesight beyond maintaining normal vision.',\n",
       "   'e2x_entail_prob': 0.9374357461929321,\n",
       "   'x2e_entail_prob': 0.3243498206138611},\n",
       "  {'statement': 'Mount Everest is over 8,000 meters tall.',\n",
       "   'label': 'SUPPORTED',\n",
       "   'evidences': [\"Mount Everest's height was first measured in 1856 as 8,840 meters.\",\n",
       "    \"Recent GPS surveys have confirmed Everest's elevation at approximately 8,848.86 meters above sea level.\",\n",
       "    'Everest is the tallest mountain on Earth by elevation above sea level.'],\n",
       "   'explanation': \"Multiple measurements, historical and modern, consistently report Everest's height above 8,000 meters.\",\n",
       "   'e2x_entail_prob': 0.6474490761756897,\n",
       "   'x2e_entail_prob': 0.017947306856513023},\n",
       "  {'statement': 'Honey never spoils.',\n",
       "   'label': 'SUPPORTED',\n",
       "   'evidences': ['Archaeologists have found pots of honey in ancient Egyptian tombs over 3,000 years old that were still edible.',\n",
       "    \"Honey's low moisture and high acidity inhibit bacterial growth, allowing it to remain unspoiled.\"],\n",
       "   'explanation': 'Due to its chemical properties, honey resists spoilage and archaeological examples show it remains edible for millennia.',\n",
       "   'e2x_entail_prob': 0.9807917475700378,\n",
       "   'x2e_entail_prob': 0.0038264794275164604},\n",
       "  {'statement': 'Honey never spoils.',\n",
       "   'label': 'NOT_SUPPORTED',\n",
       "   'evidences': ['Archaeologists have found pots of honey in ancient Egyptian tombs over 3,000 years old that were still edible.',\n",
       "    \"Honey's low moisture and high acidity inhibit bacterial growth, allowing it to remain unspoiled.\"],\n",
       "   'explanation': 'Honey spoils after a week.',\n",
       "   'e2x_entail_prob': 0.0015755320200696588,\n",
       "   'x2e_entail_prob': 0.00018953019753098488}],\n",
       " {'avg_e2x_entail_prob': 0.5895677332999185,\n",
       "  'avg_x2e_entail_prob': 0.2015648520551622})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../sample_complex.json\") as fin:\n",
    "    data = json.load(fin)\n",
    "\n",
    "evaluate_entailment(\n",
    "    data,\n",
    "    result_dir=\"output/roberta_mnli\",\n",
    "    tokenizer_path=\"roberta-large-mnli\",\n",
    "    model_path=\"roberta-large-mnli\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++\n",
      "Processing model setup: deepseek_r1_32b_cot\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\deepseek_r1_32b_cot\\covid_fact_depseek_r1_cot.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1017 items to `output\\entailment\\deepseek_r1_32b_cot/covid_fact_depseek_r1_cot.results.json`\n",
      "Averages written to `output\\entailment\\deepseek_r1_32b_cot/covid_fact_depseek_r1_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\deepseek_r1_32b_cot\\covid_fact_depseek_r1_cot.json. Time elapsed since start: 17.22 minutes, since last file: 17.22 minutes.\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\deepseek_r1_32b_cot\\hover_train_depseek-r1-cot.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2076 items to `output\\entailment\\deepseek_r1_32b_cot/hover_train_depseek-r1-cot.results.json`\n",
      "Averages written to `output\\entailment\\deepseek_r1_32b_cot/hover_train_depseek-r1-cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\deepseek_r1_32b_cot\\hover_train_depseek-r1-cot.json. Time elapsed since start: 61.69 minutes, since last file: 44.47 minutes.\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\deepseek_r1_32b_cot\\politi_hop_depseek_r1_cot.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 497 items to `output\\entailment\\deepseek_r1_32b_cot/politi_hop_depseek_r1_cot.results.json`\n",
      "Averages written to `output\\entailment\\deepseek_r1_32b_cot/politi_hop_depseek_r1_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\deepseek_r1_32b_cot\\politi_hop_depseek_r1_cot.json. Time elapsed since start: 73.43 minutes, since last file: 11.74 minutes.\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++\n",
      "Processing model setup: gpt4o_cot\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_cot\\covid_fact_gpt4o_cot.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1050 items to `output\\entailment\\gpt4o_cot/covid_fact_gpt4o_cot.results.json`\n",
      "Averages written to `output\\entailment\\gpt4o_cot/covid_fact_gpt4o_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_cot\\covid_fact_gpt4o_cot.json. Time elapsed since start: 93.01 minutes, since last file: 19.58 minutes.\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_cot\\hover_train_gpt4o_cot.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2050 items to `output\\entailment\\gpt4o_cot/hover_train_gpt4o_cot.results.json`\n",
      "Averages written to `output\\entailment\\gpt4o_cot/hover_train_gpt4o_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_cot\\hover_train_gpt4o_cot.json. Time elapsed since start: 142.13 minutes, since last file: 49.12 minutes.\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_cot\\politi_hop_gpt4o_cot.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 497 items to `output\\entailment\\gpt4o_cot/politi_hop_gpt4o_cot.results.json`\n",
      "Averages written to `output\\entailment\\gpt4o_cot/politi_hop_gpt4o_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_cot\\politi_hop_gpt4o_cot.json. Time elapsed since start: 155.01 minutes, since last file: 12.88 minutes.\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++\n",
      "Processing model setup: gpt4o_non_cot\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_non_cot\\covid_fact_gpt4o_non_cot.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1050 items to `output\\entailment\\gpt4o_non_cot/covid_fact_gpt4o_non_cot.results.json`\n",
      "Averages written to `output\\entailment\\gpt4o_non_cot/covid_fact_gpt4o_non_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_non_cot\\covid_fact_gpt4o_non_cot.json. Time elapsed since start: 173.51 minutes, since last file: 18.51 minutes.\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_non_cot\\hover_train_gpt4o_non_cot.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2050 items to `output\\entailment\\gpt4o_non_cot/hover_train_gpt4o_non_cot.results.json`\n",
      "Averages written to `output\\entailment\\gpt4o_non_cot/hover_train_gpt4o_non_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_non_cot\\hover_train_gpt4o_non_cot.json. Time elapsed since start: 219.65 minutes, since last file: 46.14 minutes.\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_non_cot\\politi_hop_gpt4o_non_cot.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 497 items to `output\\entailment\\gpt4o_non_cot/politi_hop_gpt4o_non_cot.results.json`\n",
      "Averages written to `output\\entailment\\gpt4o_non_cot/politi_hop_gpt4o_non_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_non_cot\\politi_hop_gpt4o_non_cot.json. Time elapsed since start: 232.02 minutes, since last file: 12.37 minutes.\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++\n",
      "Processing model setup: mistral_7b_NO_cot\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\mistral_7b_NO_cot\\covid_fact_mistral_7b_no_cot.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1212 items to `output\\entailment\\mistral_7b_NO_cot/covid_fact_mistral_7b_no_cot.results.json`\n",
      "Averages written to `output\\entailment\\mistral_7b_NO_cot/covid_fact_mistral_7b_no_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\mistral_7b_NO_cot\\covid_fact_mistral_7b_no_cot.json. Time elapsed since start: 255.00 minutes, since last file: 22.97 minutes.\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\mistral_7b_NO_cot\\hover_train_mistral_7b_no_cot.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2013 items to `output\\entailment\\mistral_7b_NO_cot/hover_train_mistral_7b_no_cot.results.json`\n",
      "Averages written to `output\\entailment\\mistral_7b_NO_cot/hover_train_mistral_7b_no_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\mistral_7b_NO_cot\\hover_train_mistral_7b_no_cot.json. Time elapsed since start: 301.17 minutes, since last file: 46.17 minutes.\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\mistral_7b_NO_cot\\politi_hop_mistral_7b_no_cot.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 497 items to `output\\entailment\\mistral_7b_NO_cot/politi_hop_mistral_7b_no_cot.results.json`\n",
      "Averages written to `output\\entailment\\mistral_7b_NO_cot/politi_hop_mistral_7b_no_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\mistral_7b_NO_cot\\politi_hop_mistral_7b_no_cot.json. Time elapsed since start: 313.83 minutes, since last file: 12.66 minutes.\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++\n",
      "Processing model setup: mistral__7b_cot\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\mistral__7b_cot\\covid_fact_mistral_7b_cot.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1162 items to `output\\entailment\\mistral__7b_cot/covid_fact_mistral_7b_cot.results.json`\n",
      "Averages written to `output\\entailment\\mistral__7b_cot/covid_fact_mistral_7b_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\mistral__7b_cot\\covid_fact_mistral_7b_cot.json. Time elapsed since start: 337.88 minutes, since last file: 24.06 minutes.\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\mistral__7b_cot\\hover_train_mistral_7b_cot.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2558 items to `output\\entailment\\mistral__7b_cot/hover_train_mistral_7b_cot.results.json`\n",
      "Averages written to `output\\entailment\\mistral__7b_cot/hover_train_mistral_7b_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\mistral__7b_cot\\hover_train_mistral_7b_cot.json. Time elapsed since start: 401.87 minutes, since last file: 63.99 minutes.\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\mistral__7b_cot\\politi_hop_mistral_7b_cot.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 497 items to `output\\entailment\\mistral__7b_cot/politi_hop_mistral_7b_cot.results.json`\n",
      "Averages written to `output\\entailment\\mistral__7b_cot/politi_hop_mistral_7b_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\mistral__7b_cot\\politi_hop_mistral_7b_cot.json. Time elapsed since start: 415.74 minutes, since last file: 13.87 minutes.\n"
     ]
    }
   ],
   "source": [
    "SKIP_EXISTING_RESULTS: Literal[\"auto\", \"ask\"] = \"auto\"\n",
    "\n",
    "data_path = os.path.normpath(\"../inference_outputs/converted_outputs/\")\n",
    "model_setup_dirs = os.listdir(data_path)\n",
    "\n",
    "t1 = time()\n",
    "\n",
    "for model_setup_dir in model_setup_dirs:\n",
    "    if not os.path.isdir(os.path.join(data_path, model_setup_dir)):\n",
    "        continue\n",
    "\n",
    "    print(\"\\n\\n+++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(f\"Processing model setup: {model_setup_dir}\")\n",
    "\n",
    "    dataset_files = os.listdir(os.path.join(data_path, model_setup_dir))\n",
    "    if not dataset_files:\n",
    "        print(f\"No files found in {model_setup_dir}...\")\n",
    "        raise ValueError()\n",
    "\n",
    "    for dataset_file in dataset_files:\n",
    "        if not dataset_file.endswith(\".json\"):\n",
    "            continue\n",
    "\n",
    "        t2 = time()\n",
    "        dataset_path = os.path.join(data_path, model_setup_dir, dataset_file)\n",
    "        result_dir = os.path.join(\"output\", \"entailment\", model_setup_dir)\n",
    "        stats_output_filename = f\"{dataset_file.replace('.json', '.stats.json')}\"\n",
    "        results_output_filename = f\"{dataset_file.replace('.json', '.results.json')}\"\n",
    "\n",
    "        if os.path.exists(\n",
    "            os.path.join(result_dir, stats_output_filename)\n",
    "        ) or os.path.exists(os.path.join(result_dir, results_output_filename)):\n",
    "            print(\n",
    "                f\"Either {stats_output_filename} or {results_output_filename} already exists in {result_dir}.\"\n",
    "            )\n",
    "            if SKIP_EXISTING_RESULTS == \"ask\":\n",
    "                if (\n",
    "                    input(\"Do you want to recreate these files? (y/n): \")\n",
    "                    .strip()\n",
    "                    .lower()\n",
    "                    != \"y\"\n",
    "                ):\n",
    "                    print(\"Skipping these files...\")\n",
    "                    continue\n",
    "            elif SKIP_EXISTING_RESULTS == \"auto\":\n",
    "                print(\n",
    "                    f\"Skipping {dataset_path} as results already exist in {result_dir}. Please check manually if results are valid.\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "        print(f\"\\nEvaluating {dataset_path}...\")\n",
    "        with open(dataset_path, encoding=\"utf-8\") as fin:\n",
    "            data = json.load(fin)\n",
    "\n",
    "        evaluate_entailment(\n",
    "            data=data,\n",
    "            stats_filename=stats_output_filename,\n",
    "            results_filename=results_output_filename,\n",
    "            result_dir=result_dir,\n",
    "            tokenizer_path=\"roberta-large-mnli\",\n",
    "            model_path=\"roberta-large-mnli\",\n",
    "        )\n",
    "        t3 = time()\n",
    "        print(\n",
    "            f\"Finished evaluating {dataset_path}. Time elapsed since start: {(t3 - t1) / 60:.2f} minutes, since last file: {(t3 - t2) / 60:.2f} minutes.\"\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
