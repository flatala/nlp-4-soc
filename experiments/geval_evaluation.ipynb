{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1dafa1f",
   "metadata": {},
   "source": [
    "# G-EVAL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6309f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from time import time\n",
    "from typing import Literal\n",
    "from faithfulness_eval_utils.geval import evaluate_geval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526454cc",
   "metadata": {},
   "source": [
    "## Example loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7da71211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 5 items to `output/geval/results.json`\n",
      "Averages written to `output/geval/stats.json`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'statement': \"Shakespeare wrote 'Romeo and Juliet'.\",\n",
       "   'explanation': \"Historical records and publication attributions confirm that Shakespeare wrote 'Romeo and Juliet'.\",\n",
       "   'evidences': [\"William Shakespeare is credited as the author of the play 'Romeo and Juliet'.\",\n",
       "    \"'Romeo and Juliet' was first published in 1597 and is attributed to Shakespeare.\"],\n",
       "   'label': 'SUPPORTED',\n",
       "   'q1_factual_claims_not_in_evidence': '**No**, the explanation does not make any factual claims not found in the evidence.',\n",
       "   'q2_reflects_key_points': '**Yes**, the explanation faithfully reflects the key points in the evidence, specifically highlighting the historical records and publication attributions that support Shakespeare\\'s authorship of \"Romeo and Juliet\".',\n",
       "   'faithfulness_score_0_5': 5.0,\n",
       "   'justification': '',\n",
       "   'raw_response': 'Here are my evaluations:\\n\\n1. **No**, the explanation does not make any factual claims not found in the evidence.\\n\\n2. **Yes**, the explanation faithfully reflects the key points in the evidence, specifically highlighting the historical records and publication attributions that support Shakespeare\\'s authorship of \"Romeo and Juliet\".\\n\\n3. Faithfulness Score: **5/5**\\n\\nJustification: The explanation only uses information present in the evidence, accurately summarizing the supporting points (historical records and publication attributions) without adding any unsupported claims or hallucinations.'},\n",
       "  {'statement': 'Eating carrots improves eyesight.',\n",
       "   'explanation': 'While carrots provide vitamin A, there is no evidence they improve eyesight beyond maintaining normal vision.',\n",
       "   'evidences': ['Carrots contain beta-carotene, which the body converts to vitamin A, a nutrient important for vision.',\n",
       "    'No clinical evidence shows that eating carrots prevents or cures vision problems beyond normal health benefits.'],\n",
       "   'label': 'NOT_SUPPORTED',\n",
       "   'q1_factual_claims_not_in_evidence': \"**No**: The explanation only summarizes the key points from the evidence, without making any additional claims that aren't supported by the provided data.\",\n",
       "   'q2_reflects_key_points': '**Yes**: The explanation accurately reflects the main points from the evidence, including the role of beta-carotene in vitamin A production and the lack of clinical evidence supporting improved eyesight beyond normal vision maintenance.',\n",
       "   'faithfulness_score_0_5': 5.0,\n",
       "   'justification': '',\n",
       "   'raw_response': \"Here are my evaluations:\\n\\n1. **No**: The explanation only summarizes the key points from the evidence, without making any additional claims that aren't supported by the provided data.\\n\\n2. **Yes**: The explanation accurately reflects the main points from the evidence, including the role of beta-carotene in vitamin A production and the lack of clinical evidence supporting improved eyesight beyond normal vision maintenance.\\n\\n3. Faithfulness Score: **5/5**\\nJustification: The explanation is entirely faithful to the evidence, without adding any unsupported claims or interpretations that aren't justified by the provided data. It accurately summarizes the key points from the evidence, making it a highly faithful representation of the original information.\"},\n",
       "  {'statement': 'Mount Everest is over 8,000 meters tall.',\n",
       "   'explanation': \"Multiple measurements, historical and modern, consistently report Everest's height above 8,000 meters.\",\n",
       "   'evidences': [\"Mount Everest's height was first measured in 1856 as 8,840 meters.\",\n",
       "    \"Recent GPS surveys have confirmed Everest's elevation at approximately 8,848.86 meters above sea level.\",\n",
       "    'Everest is the tallest mountain on Earth by elevation above sea level.'],\n",
       "   'label': 'SUPPORTED',\n",
       "   'q1_factual_claims_not_in_evidence': '**No**, the explanation does not make any factual claims not found in the evidence.',\n",
       "   'q2_reflects_key_points': \"**Yes**, the explanation faithfully reflects the key points in the evidence, specifically mentioning multiple measurements and reporting Everest's height above 8,000 meters, which is supported by the provided data.\",\n",
       "   'faithfulness_score_0_5': 5.0,\n",
       "   'justification': '',\n",
       "   'raw_response': \"Here are my evaluations:\\n\\n1. **No**, the explanation does not make any factual claims not found in the evidence.\\n\\n2. **Yes**, the explanation faithfully reflects the key points in the evidence, specifically mentioning multiple measurements and reporting Everest's height above 8,000 meters, which is supported by the provided data.\\n\\n3. Faithfulness Score: **5/5**\\nJustification: The explanation only uses information present in the evidence, accurately summarizing the historical measurement and recent GPS surveys that confirm Everest's elevation above 8,000 meters.\"},\n",
       "  {'statement': 'Honey never spoils.',\n",
       "   'explanation': 'Due to its chemical properties, honey resists spoilage and archaeological examples show it remains edible for millennia.',\n",
       "   'evidences': ['Archaeologists have found pots of honey in ancient Egyptian tombs over 3,000 years old that were still edible.',\n",
       "    \"Honey's low moisture and high acidity inhibit bacterial growth, allowing it to remain unspoiled.\"],\n",
       "   'label': 'SUPPORTED',\n",
       "   'q1_factual_claims_not_in_evidence': '**No**, the explanation does not make any factual claims not found in the evidence.',\n",
       "   'q2_reflects_key_points': \"**Yes**, the explanation faithfully reflects the key points in the evidence, specifically highlighting honey's chemical properties and its resistance to spoilage, which is supported by both archaeological examples and scientific explanations (low moisture and high acidity).\",\n",
       "   'faithfulness_score_0_5': 5.0,\n",
       "   'justification': '',\n",
       "   'raw_response': \"Here are my evaluations:\\n\\n1. **No**, the explanation does not make any factual claims not found in the evidence.\\n\\n2. **Yes**, the explanation faithfully reflects the key points in the evidence, specifically highlighting honey's chemical properties and its resistance to spoilage, which is supported by both archaeological examples and scientific explanations (low moisture and high acidity).\\n\\n3. Faithfulness Score: **5/5**\\n\\nJustification: The explanation only uses information present in the evidence, accurately summarizing the supporting points without adding any unsupported claims or hallucinations. It provides a clear and concise reflection of the key ideas presented in the evidence.\"},\n",
       "  {'statement': 'Honey never spoils.',\n",
       "   'explanation': 'Honey spoils after a week.',\n",
       "   'evidences': ['Archaeologists have found pots of honey in ancient Egyptian tombs over 3,000 years old that were still edible.',\n",
       "    \"Honey's low moisture and high acidity inhibit bacterial growth, allowing it to remain unspoiled.\"],\n",
       "   'label': 'NOT_SUPPORTED',\n",
       "   'q1_factual_claims_not_in_evidence': '**Yes**, the explanation makes a factual claim (\"Honey spoils after a week.\") that is not found in the evidence.',\n",
       "   'q2_reflects_key_points': '**No**, the explanation does not faithfully reflect the key points in the evidence, which suggest that honey can remain unspoiled for a long time due to its low moisture and high acidity.',\n",
       "   'faithfulness_score_0_5': 0.0,\n",
       "   'justification': '',\n",
       "   'raw_response': 'Here are my evaluations:\\n\\n1. **Yes**, the explanation makes a factual claim (\"Honey spoils after a week.\") that is not found in the evidence.\\n2. **No**, the explanation does not faithfully reflect the key points in the evidence, which suggest that honey can remain unspoiled for a long time due to its low moisture and high acidity.\\n3. Faithfulness Score: **0/5**. The explanation directly contradicts the evidence and makes an unsupported claim about honey spoiling after a week.\\n\\nJustification: The explanation is not faithful because it introduces a new, unsubstantiated claim that is opposite of what the evidence suggests.'}],\n",
       " {'avg_geval_score_0_5': 4.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../sample_complex.json\") as fin:\n",
    "    data = json.load(fin)\n",
    "\n",
    "await evaluate_geval(\n",
    "    data=data,\n",
    "    result_dir=\"output/geval\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36351a67",
   "metadata": {},
   "source": [
    "## Evaluating all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2aec05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++\n",
      "Processing model setup: deepseek_r1_32b_cot\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\deepseek_r1_32b_cot\\covid_fact_depseek_r1_cot.json...\n",
      "Saved 1017 items to `output\\geval\\deepseek_r1_32b_cot/covid_fact_depseek_r1_cot.results.json`\n",
      "Averages written to `output\\geval\\deepseek_r1_32b_cot/covid_fact_depseek_r1_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\deepseek_r1_32b_cot\\covid_fact_depseek_r1_cot.json. Time elapsed since start: 41.17 minutes, since last file: 41.17 minutes.\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\deepseek_r1_32b_cot\\hover_train_depseek-r1-cot.json...\n",
      "Saved 2076 items to `output\\geval\\deepseek_r1_32b_cot/hover_train_depseek-r1-cot.results.json`\n",
      "Averages written to `output\\geval\\deepseek_r1_32b_cot/hover_train_depseek-r1-cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\deepseek_r1_32b_cot\\hover_train_depseek-r1-cot.json. Time elapsed since start: 113.27 minutes, since last file: 72.10 minutes.\n",
      "Either politi_hop_depseek_r1_cot.stats.json or politi_hop_depseek_r1_cot.results.json already exists in output\\geval\\deepseek_r1_32b_cot.\n",
      "Skipping ..\\inference_outputs\\converted_outputs\\deepseek_r1_32b_cot\\politi_hop_depseek_r1_cot.json as results already exist in output\\geval\\deepseek_r1_32b_cot. Please check manually if results are valid.\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++\n",
      "Processing model setup: gpt4o_cot\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_cot\\covid_fact_gpt4o_cot.json...\n",
      "Saved 1050 items to `output\\geval\\gpt4o_cot/covid_fact_gpt4o_cot.results.json`\n",
      "Averages written to `output\\geval\\gpt4o_cot/covid_fact_gpt4o_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_cot\\covid_fact_gpt4o_cot.json. Time elapsed since start: 155.22 minutes, since last file: 41.95 minutes.\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_cot\\hover_train_gpt4o_cot.json...\n",
      "Saved 2050 items to `output\\geval\\gpt4o_cot/hover_train_gpt4o_cot.results.json`\n",
      "Averages written to `output\\geval\\gpt4o_cot/hover_train_gpt4o_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_cot\\hover_train_gpt4o_cot.json. Time elapsed since start: 227.02 minutes, since last file: 71.80 minutes.\n",
      "Either politi_hop_gpt4o_cot.stats.json or politi_hop_gpt4o_cot.results.json already exists in output\\geval\\gpt4o_cot.\n",
      "Skipping ..\\inference_outputs\\converted_outputs\\gpt4o_cot\\politi_hop_gpt4o_cot.json as results already exist in output\\geval\\gpt4o_cot. Please check manually if results are valid.\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++\n",
      "Processing model setup: gpt4o_non_cot\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_non_cot\\covid_fact_gpt4o_non_cot.json...\n",
      "Saved 1050 items to `output\\geval\\gpt4o_non_cot/covid_fact_gpt4o_non_cot.results.json`\n",
      "Averages written to `output\\geval\\gpt4o_non_cot/covid_fact_gpt4o_non_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_non_cot\\covid_fact_gpt4o_non_cot.json. Time elapsed since start: 268.77 minutes, since last file: 41.74 minutes.\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_non_cot\\hover_train_gpt4o_non_cot.json...\n",
      "Saved 2050 items to `output\\geval\\gpt4o_non_cot/hover_train_gpt4o_non_cot.results.json`\n",
      "Averages written to `output\\geval\\gpt4o_non_cot/hover_train_gpt4o_non_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_non_cot\\hover_train_gpt4o_non_cot.json. Time elapsed since start: 339.35 minutes, since last file: 70.58 minutes.\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_non_cot\\politi_hop_gpt4o_non_cot.json...\n",
      "Saved 497 items to `output\\geval\\gpt4o_non_cot/politi_hop_gpt4o_non_cot.results.json`\n",
      "Averages written to `output\\geval\\gpt4o_non_cot/politi_hop_gpt4o_non_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\gpt4o_non_cot\\politi_hop_gpt4o_non_cot.json. Time elapsed since start: 355.41 minutes, since last file: 16.06 minutes.\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++\n",
      "Processing model setup: mistral_7b_NO_cot\n",
      "Either covid_fact_mistral_7b_no_cot.stats.json or covid_fact_mistral_7b_no_cot.results.json already exists in output\\geval\\mistral_7b_NO_cot.\n",
      "Skipping ..\\inference_outputs\\converted_outputs\\mistral_7b_NO_cot\\covid_fact_mistral_7b_no_cot.json as results already exist in output\\geval\\mistral_7b_NO_cot. Please check manually if results are valid.\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\mistral_7b_NO_cot\\hover_train_mistral_7b_no_cot.json...\n",
      "Saved 2013 items to `output\\geval\\mistral_7b_NO_cot/hover_train_mistral_7b_no_cot.results.json`\n",
      "Averages written to `output\\geval\\mistral_7b_NO_cot/hover_train_mistral_7b_no_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\mistral_7b_NO_cot\\hover_train_mistral_7b_no_cot.json. Time elapsed since start: 425.82 minutes, since last file: 70.41 minutes.\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\mistral_7b_NO_cot\\politi_hop_mistral_7b_no_cot.json...\n",
      "Saved 497 items to `output\\geval\\mistral_7b_NO_cot/politi_hop_mistral_7b_no_cot.results.json`\n",
      "Averages written to `output\\geval\\mistral_7b_NO_cot/politi_hop_mistral_7b_no_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\mistral_7b_NO_cot\\politi_hop_mistral_7b_no_cot.json. Time elapsed since start: 441.66 minutes, since last file: 15.83 minutes.\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++\n",
      "Processing model setup: mistral__7b_cot\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\mistral__7b_cot\\covid_fact_mistral_7b_cot.json...\n",
      "Saved 1162 items to `output\\geval\\mistral__7b_cot/covid_fact_mistral_7b_cot.results.json`\n",
      "Averages written to `output\\geval\\mistral__7b_cot/covid_fact_mistral_7b_cot.stats.json`\n",
      "Finished evaluating ..\\inference_outputs\\converted_outputs\\mistral__7b_cot\\covid_fact_mistral_7b_cot.json. Time elapsed since start: 487.41 minutes, since last file: 45.75 minutes.\n",
      "\n",
      "Evaluating ..\\inference_outputs\\converted_outputs\\mistral__7b_cot\\hover_train_mistral_7b_cot.json...\n"
     ]
    }
   ],
   "source": [
    "SKIP_EXISTING_RESULTS: Literal[\"auto\", \"ask\"] = \"auto\"  # auto for the overnight run\n",
    "\n",
    "data_path = os.path.normpath(\"../inference_outputs/converted_outputs/\")\n",
    "model_setup_dirs = os.listdir(data_path)\n",
    "\n",
    "t1 = time()\n",
    "\n",
    "for model_setup_dir in model_setup_dirs:\n",
    "    if not os.path.isdir(os.path.join(data_path, model_setup_dir)):\n",
    "        continue\n",
    "\n",
    "    print(\"\\n\\n+++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(f\"Processing model setup: {model_setup_dir}\")\n",
    "\n",
    "    dataset_files = os.listdir(os.path.join(data_path, model_setup_dir))\n",
    "    if not dataset_files:\n",
    "        print(f\"No files found in {model_setup_dir}...\")\n",
    "        raise ValueError()\n",
    "\n",
    "    for dataset_file in dataset_files:\n",
    "        if not dataset_file.endswith(\".json\"):\n",
    "            continue\n",
    "\n",
    "        t2 = time()\n",
    "        dataset_path = os.path.join(data_path, model_setup_dir, dataset_file)\n",
    "        result_dir = os.path.join(\"output\", \"geval\", model_setup_dir)\n",
    "        stats_output_filename = f\"{dataset_file.replace('.json', '.stats.json')}\"\n",
    "        results_output_filename = f\"{dataset_file.replace('.json', '.results.json')}\"\n",
    "\n",
    "        if os.path.exists(\n",
    "            os.path.join(result_dir, stats_output_filename)\n",
    "        ) or os.path.exists(os.path.join(result_dir, results_output_filename)):\n",
    "            print(\n",
    "                f\"Either {stats_output_filename} or {results_output_filename} already exists in {result_dir}.\"\n",
    "            )\n",
    "            if SKIP_EXISTING_RESULTS == \"ask\":\n",
    "                if (\n",
    "                    input(\"Do you want to recreate these files? (y/n): \")\n",
    "                    .strip()\n",
    "                    .lower()\n",
    "                    != \"y\"\n",
    "                ):\n",
    "                    print(\"Skipping these files...\")\n",
    "                    continue\n",
    "            elif SKIP_EXISTING_RESULTS == \"auto\":\n",
    "                print(\n",
    "                    f\"Skipping {dataset_path} as results already exist in {result_dir}. Please check manually if results are valid.\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "        print(f\"\\nEvaluating {dataset_path}...\")\n",
    "        with open(dataset_path, encoding=\"utf-8\") as fin:\n",
    "            data = json.load(fin)\n",
    "\n",
    "        await evaluate_geval(\n",
    "            data=data,\n",
    "            result_dir=result_dir,\n",
    "            stats_filename=stats_output_filename,\n",
    "            results_filename=results_output_filename,\n",
    "        )\n",
    "        t3 = time()\n",
    "        print(\n",
    "            f\"Finished evaluating {dataset_path}. Time elapsed since start: {(t3 - t1) / 60:.2f} minutes, since last file: {(t3 - t2) / 60:.2f} minutes.\"\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
